{"cells":[{"cell_type":"code","source":["sqlDF = spark.sql(\"SELECT msno, MAX(transaction_date) as transaction_date, first(payment_method_id) as payment_method_id, AVG(payment_plan_days) as payment_plan_days,  first(plan_list_price) as plan_list_price, first(actual_amount_paid) as actual_amount_paid, first(is_auto_renew) as is_auto_renew, MAX(membership_expire_date) as membership_expire_date, first(is_cancel) as is_cancel FROM transactions_csv GROUP BY msno \")\ndisplay(sqlDF)\n\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["sqlDF2 = spark.sql(\"SELECT msno, AVG(num_25) AS num_25_avg, AVG(num_50) AS num_50_avg, AVG(num_75) AS num_75_avg, AVG(num_985) AS num_985_avg, SUM(num_unq) AS num_unq_avg, AVG(total_secs) AS total_secs_avg FROM user_logs GROUP BY msno \")\ndisplay(sqlDF2)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["sqlDF3 = spark.sql(\"SELECT * FROM train_csv\")\nfinal = sqlDF.join(sqlDF2, 'msno', \"outer\")\nfinal2 = final.join(sqlDF3, 'msno', \"outer\")\nfinal3 = final2.na.drop(subset=[\"total_secs_avg\"])\nfinal4 = final3.na.drop(subset=[\"is_churn\"])\nprint(final4)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(\n    inputCols=[\"num_25_avg\", \"num_50_avg\", \"num_75_avg\", \"num_unq_avg\", \"transaction_date\", \"payment_method_id\", \"payment_plan_days\", \"plan_list_price\",  \"actual_amount_paid\", \"is_auto_renew\", \"membership_expire_date\", \"is_cancel\",  \"total_secs_avg\"], outputCol=\"features\")\nfinal_df = assembler.transform(final4)\nfinal_df.select(\"features\").show(4, False)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n\nlabelIndexer = StringIndexer(inputCol=\"is_churn\", outputCol=\"indexedLabel\").fit(final_df)\n\nfeatureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=10).fit(final_df)\n  \n  \n  # Split the data into training and test sets (30% held out for testing)\n(trainingData, testData) = final_df.randomSplit([0.7, 0.3])\n\n# Train a GBT model.\ngbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n\n# Chain indexers and GBT in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n\n# Train model.  This also runs the indexers.\nmodel = pipeline.fit(trainingData)\n\n# Make predictions.\npredictions = model.transform(testData)\n\n# Select example rows to display.\npredictions.select(\"prediction\", \"indexedLabel\", \"features\").show(100)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Error = %g\" % (1.0 - accuracy))\n\ngbtModel = model.stages[2]\nprint(gbtModel)  # summary only"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["print(\"Test Error = %g\" % (1.0 - accuracy))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(100)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"KKBOXDatamanip","notebookId":1050291526581115},"nbformat":4,"nbformat_minor":0}
